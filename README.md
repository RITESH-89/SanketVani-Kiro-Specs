# SanketVani-Kiro-Specs
An AI-powered assistive system enabling real-time two-way communication between sign language users and the hearing world.

ğŸŒ SanketVani â€“ Inclusive Communication Platform

Giving Voice to Hands | Turning Silence into Connection

ğŸ§© Overview

SanketVani is an AI-powered assistive communication platform designed to bridge the communication gap between deaf / speech-impaired individuals and the hearing community.

Using computer vision, machine learning, and speech technologies, SanketVani enables real-time, two-way communication between sign language, text, and voice â€” all without any special hardware.

Accessibility is not charity â€” it is equality.

â— Problem Statement

Millions of deaf and speech-impaired individuals face daily communication barriers in:

Education

Healthcare

Public services

Workplaces

Emergency situations

Key Challenges

Heavy dependence on human interpreters

Existing tools are costly, slow, or one-directional

Typing-based communication is unnatural and limiting

No unified, real-time solution available

ğŸ’¡ Solution â€“ SanketVani

SanketVani provides a single, integrated platform that supports:

âœ‹ Sign â†’ Text

âœ‹ Sign â†’ Speech

ğŸ¤ Speech â†’ Sign

âŒ¨ï¸ Text â†’ Sign

ğŸ“„ PDF / DOC â†’ Sign

ğŸ¥ Live Video Call Integration (Signâ€“Speech overlay)

All processing is done using a camera + AI software, ensuring low cost, portability, and scalability.

âš™ï¸ Technology Stack
Layer	Technologies
Programming	Python
Computer Vision	OpenCV, MediaPipe
Machine Learning	TensorFlow (CNN)
Speech Processing	SpeechRecognition, pyttsx3 / SAPI
UI / Integration	Tkinter, Virtual Camera
Hardware	Webcam / Laptop / Mobile Camera
ğŸ§  Algorithms Used

MediaPipe Hand Landmark Detection
â†’ Tracks 21 key hand points in real time

Convolutional Neural Network (CNN)
â†’ Classifies gestures with ~92% accuracy

Speech-to-Text (STT)
â†’ Converts spoken language into text

Text-to-Speech (TTS)
â†’ Converts recognized text into natural voice

ğŸ”„ System Workflow

Camera captures hand gesture or voice input

AI model processes the input in real time

Gesture is classified using CNN

Output generated as text, speech, or sign animation

Reverse flow enables speech/text to sign conversion

Optional overlay during live video calls

ğŸ“Š Results & Performance

âœ… Accuracy: ~92% (live prototype testing)

âš¡ Response Time: ~550â€“800 milliseconds

ğŸ“· Hardware: Standard webcam

ğŸŒ Mode: Offline + Online support

ğŸ§ª Validation: Field testing at NGOs (Navjeevan, SOS)

ğŸŒ Impact & Use Cases

ğŸ“ Inclusive education for deaf students

ğŸ¥ Improved doctorâ€“patient communication

ğŸ¢ Accessibility in government offices

ğŸš¨ Emergency communication support

ğŸ‘¥ Independent daily conversations

SanketVani restores dignity, independence, and equality.

ğŸ“ˆ Market Potential

India: ~6+ million deaf & speech-impaired individuals

Global: ~60+ million potential users

Target Users

Individuals

NGOs & special schools

Government institutions

Healthcare centers

ğŸš€ Future Scope

Regional & multilingual sign support

Mobile application (Android / iOS)

AR/VR sign avatars

Government kiosk deployment

Offline-first optimization

ğŸ“ Project Structure
SanketVani/
â”œâ”€â”€ requirements.md        # Kiro-generated requirements
â”œâ”€â”€ design.md              # Kiro-generated system design
â”œâ”€â”€ README.md              # Project documentation
â”œâ”€â”€ texttosign.py
â”œâ”€â”€ voicetosign.py
â”œâ”€â”€ sign_recognition.py
â”œâ”€â”€ videocall_virtual_cam.py
â”œâ”€â”€ asl_signs/
â””â”€â”€ assets/

ğŸ“œ Documentation

This project follows Kiroâ€™s Spec â†’ Design workflow to generate:

requirements.md

design.md

These files define the functional requirements and system architecture in a professional, industry-standard format.

ğŸ‘¨â€ğŸ’» Author

Ritesh Pravin Paithankar
Developer & Researcher
ğŸ“ India

â¤ï¸ Final Note

SanketVani is not just a technology â€” it is a movement.

It turns hands into voice and silence into connection.
